{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/guzzo/anaconda3/envs/find-out/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/guzzo/anaconda3/envs/find-out/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/guzzo/anaconda3/envs/find-out/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/guzzo/anaconda3/envs/find-out/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/guzzo/anaconda3/envs/find-out/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/guzzo/anaconda3/envs/find-out/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in index: 22101\n",
      "\n",
      " Evaluation of model with ALL layers fine-tuned:\n",
      "\n",
      " Evaluation of model with LAST layer fine-tuned:\n",
      "\n",
      " Evaluation of model trained from scratch:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/guzzo/anaconda3/envs/find-out/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\"input_length\" is 140, but received input has shape (None, None, 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bd19b623da49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m### EDA of PREDICTIONS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mdf_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturns_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_original_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0mdf_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturns_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_fine_tuned_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mdf_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturns_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_fine_tuned_model_last\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-bd19b623da49>\u001b[0m in \u001b[0;36mreturns_predictions\u001b[0;34m(path_to_model, differences)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_target_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/find-out/src/models/hatespeech/model_translearn_hatespeech.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(word_embedding_matrix, vocab_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_embedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m140\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         )\n\u001b[1;32m     19\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/find-out/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/anaconda3/envs/find-out/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m             if all([s is not None\n\u001b[1;32m    473\u001b[0m                     for s in to_list(input_shape)]):\n\u001b[0;32m--> 474\u001b[0;31m                 \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/find-out/lib/python3.7/site-packages/keras/layers/embeddings.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 raise ValueError(\n\u001b[1;32m    126\u001b[0m                     \u001b[0;34m'\"input_length\" is %s, but received input has shape %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                     (str(self.input_length), str(input_shape)))\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: \"input_length\" is 140, but received input has shape (None, None, 40)"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from src.data.preprocess.dataturks.preprocess_translearn_hatespeech import create_nn_sets\n",
    "from src.data.preprocess.exploratory_data_analysis_helpers import contains_bigram\n",
    "from src.data.preprocess.exploratory_data_analysis_helpers import \\\n",
    "    density_of_curse_words_in_total_corpus, generate_ngrams, \\\n",
    "    count_pejorative_bigrams\n",
    "from src.evaluation.hatespeech.evaluation_translearn_hatespeech import evaluate_best_model, get_predictions, \\\n",
    "    draw_wordcloud\n",
    "from src.models.hatespeech.model_translearn_hatespeech import fine_tune_model, create_model\n",
    "\n",
    "np.random.seed(42)\n",
    "vocab_size = 10000\n",
    "\n",
    "path_to_target_data = \"../../data/external/hatespeech/clean_sexism_dataset.csv\"\n",
    "path_to_original_model = \"../../models/example_dataturks.h5\"\n",
    "path_to_fine_tuned_model = \"../../models/fine_tuned.h5\"\n",
    "path_to_fine_tuned_model_last = \"../../models/fine_tuned_last_layer.h5\"\n",
    "path_to_sexist_model = \"../../models/zeerak_model.h5\"\n",
    "fig_path=\"../../reports/hatespeech/figures/\"\n",
    "\n",
    "datasets = create_nn_sets(path_to_target_data, vocab_size)\n",
    "# fine_tune_model(path_to_original_model, path_to_fine_tuned_model, datasets)\n",
    "print(\"\\n Evaluation of model with ALL layers fine-tuned:\")\n",
    "#evaluate_best_model(path_to_fine_tuned_model, datasets[4], datasets[5], datasets[6], 10000)\n",
    "# fine_tune_model(path_to_original_model, path_to_fine_tuned_model2, datasets)\n",
    "print(\"\\n Evaluation of model with LAST layer fine-tuned:\")\n",
    "# evaluate_best_model(path_to_fine_tuned_model_last, datasets[4], datasets[5], datasets[6], 10000)\n",
    "# train_model(path_to_sexist_model, datasets, vocab_size)\n",
    "print(\"\\n Evaluation of model trained from scratch:\")\n",
    "# evaluate_best_model(path_to_sexist_model, datasets[4], datasets[5], datasets[6], 10000)\n",
    "\n",
    "def returns_predictions(path_to_model, differences=False):\n",
    "    \"\"\" Returns the dataframe with only the rows where the labeling is different\n",
    "    Args:\n",
    "        path_to_model (str) : the path the to model to be studied.\n",
    "    Returns:\n",
    "        df (pandas df) : the dataframe containing rows where the labeling was different.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path_to_target_data)\n",
    "    best_model = create_model(datasets[6], vocab_size)\n",
    "    best_model.load_weights(path_to_model)\n",
    "    predictions = get_predictions(best_model, datasets[4])\n",
    "    df_pred = pd.DataFrame({\"prediction\": predictions})\n",
    "    df_test = data.loc[datasets[5].index, :].reset_index()\n",
    "    df = pd.concat([df_test, df_pred], axis=1)\n",
    "    if differences == False:\n",
    "        return df\n",
    "    else:\n",
    "        return df.loc[df.loc[:, \"label\"] != df.loc[:, \"prediction\"]]\n",
    "\n",
    "def returns_misogynistic_predictions(df, misogynistic=True):\n",
    "    \"\"\"Returns the predicted or not misogynistic data.\"\"\"\n",
    "    if misogynistic == True:\n",
    "        return df.loc[df.loc[:, \"prediction\"] == 1]\n",
    "    else:\n",
    "        return df.loc[df.loc[:, \"prediction\"] == 0]\n",
    "\n",
    "\n",
    "### TOTAL CORPUS ANALYSIS\n",
    "\n",
    "## Density of CW\n",
    "total_corpus = pd.read_csv(path_to_target_data)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax = density_of_curse_words_in_total_corpus(total_corpus, \"total_corpus\").plot.bar()\n",
    "ax.set_ylabel('Density of Curse Words')\n",
    "ax.set_title('Curse Words')\n",
    "ax.set_title('Density of Curse Words in Whole Corpus', fontsize=12)\n",
    "plt.savefig(fig_path+\"curse_words_total_corpus.png\")\n",
    "plt.show()\n",
    "\n",
    "## Word Cloud\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "ax.imshow(draw_wordcloud(total_corpus['text']))\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "ax.set_title('Wordcloud of Total Corpus', fontsize=12)\n",
    "plt.savefig(fig_path+\"translearn_wordcloud_total_corpus.png\")\n",
    "\n",
    "\n",
    "### EDA of PREDICTIONS\n",
    "df_original = returns_predictions(path_to_original_model)\n",
    "df_all = returns_predictions(path_to_fine_tuned_model)\n",
    "df_last = returns_predictions(path_to_fine_tuned_model_last)\n",
    "df_sexist = returns_predictions(path_to_sexist_model)\n",
    "\n",
    "## Density of CW\n",
    "misogynistic_original = density_of_curse_words_in_total_corpus(returns_misogynistic_predictions(df_original),\n",
    "                                                               \"misogynistic_original\")\n",
    "misogynistic_all = density_of_curse_words_in_total_corpus(returns_misogynistic_predictions(df_all), \"misogynistic_all\")\n",
    "misogynistic_last = density_of_curse_words_in_total_corpus(returns_misogynistic_predictions(df_last),\n",
    "                                                           \"misogynistic_last\")\n",
    "misogynistic_sexist = density_of_curse_words_in_total_corpus(returns_misogynistic_predictions(df_sexist),\n",
    "                                                             \"misogynistic_sexist\")\n",
    "not_misogynistic_original = density_of_curse_words_in_total_corpus(\n",
    "    returns_misogynistic_predictions(df_original, misogynistic=False), \"not_misogynistic\")\n",
    "not_misogynistic_all = density_of_curse_words_in_total_corpus(\n",
    "    returns_misogynistic_predictions(df_all, misogynistic=False), \"not_misogynistic_all\")\n",
    "not_misogynistic_last = density_of_curse_words_in_total_corpus(\n",
    "    returns_misogynistic_predictions(df_last, misogynistic=False), \"not_misogynistic_last\")\n",
    "not_misogynistic_sexist = density_of_curse_words_in_total_corpus(\n",
    "    returns_misogynistic_predictions(df_sexist, misogynistic=False), \"not_misogynistic_sexist\")\n",
    "\n",
    "pd.concat([misogynistic_original, misogynistic_all, misogynistic_last, misogynistic_sexist], axis=1).plot.bar()\n",
    "plt.title(\"Density of Curse Words in Misogynistic Labeled Corpus using Different Models\")\n",
    "plt.ylabel(\"Density of Curse Words\")\n",
    "plt.xlabel(\"Curse Words\")\n",
    "plt.savefig(fig_path+\"misogynistic_cursewords_models_corpus.png\")\n",
    "plt.show()\n",
    "\n",
    "pd.concat([not_misogynistic_original, not_misogynistic_all, not_misogynistic_last, not_misogynistic_sexist], axis=1).plot.bar()\n",
    "plt.title(\"Density of Curse Words in Non Misogynistic Labeled Corpus using Different Models\")\n",
    "plt.ylabel(\"Density of Curse Words\")\n",
    "plt.xlabel(\"Curse Words\")\n",
    "plt.savefig(fig_path+\"not_misogynistic_cursewords_models_corpus.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Word Clouds\n",
    "fig, ax = plt.subplots(2, 4, sharey=True, figsize=(10, 10))\n",
    "fig.suptitle(\"Wordclouds of Misogynistic and Non-Misogynisitic Words in Corpus using Different Models\")\n",
    "titles = [\"Original dataturks dataset model\", \"ALL layers re-tuned model\", \"Last layer re-tuned model\",\n",
    "          \"Trained from scratch\"]\n",
    "dfs = [df_original, df_all, df_last, df_sexist]\n",
    "\n",
    "\n",
    "def plot_wordclouds(data, row, column, title, misogynistic=True):\n",
    "    if misogynistic == True:\n",
    "        ax[row, column].imshow(draw_wordcloud(returns_misogynistic_predictions(data)['text']))\n",
    "        ax[row, column].set_title(title)\n",
    "        ax[row, column].xaxis.set_visible(False)\n",
    "        ax[row, column].yaxis.set_visible(False)\n",
    "        return ax\n",
    "    else:\n",
    "        ax[row, column].imshow(draw_wordcloud(returns_misogynistic_predictions(data, misogynistic=False)['text']))\n",
    "        ax[row, column].set_title(title)\n",
    "        ax[row, column].xaxis.set_visible(False)\n",
    "        ax[row, column].yaxis.set_visible(False)\n",
    "        return ax\n",
    "for row in range(0, 2):\n",
    "    for column in range(0, 4):\n",
    "        if row == 0:\n",
    "            plot_wordclouds(dfs[column], row, column, titles[column])\n",
    "        else:\n",
    "            plot_wordclouds(dfs[column], row, column, titles[column], misogynistic=False)\n",
    "plt.savefig(fig_path+\"labeled_text.png\")\n",
    "plt.show()\n",
    "\n",
    "## generate_ngrams\n",
    "bigrams = df_original['text'].apply(lambda tweet: generate_ngrams(tweet, 2))\n",
    "df_bigrams = pd.DataFrame(bigram for bigram in bigrams)\n",
    "df_bigrams = df_bigrams.fillna(\"no bigram\")\n",
    "\n",
    "ADJECTIVE = [\"slut\"]\n",
    "FEMALE = [\"women\", \"woman\"]\n",
    "\n",
    "all_bigrams = []\n",
    "for i in range(0, len(df_bigrams.columns)):\n",
    "    all_bigrams.append(df_bigrams[i].apply(lambda bigram: contains_bigram(bigram, ADJECTIVE, FEMALE)))\n",
    "\n",
    "counts = count_pejorative_bigrams(all_bigrams)\n",
    "df_bigrams_counts = pd.DataFrame(counts, columns=[\"bigrams\", \"counts\"]).groupby(\"bigrams\").count().plot.bar()\n",
    "plt.show()\n",
    "\n",
    "### ERROR ANALYSIS - WHAT WE GOT WRONG\n",
    "incorrect_df_original = returns_predictions(path_to_original_model, differences=True)\n",
    "incorrect_df_all = returns_predictions(path_to_fine_tuned_model, differences=True)\n",
    "incorrect_df_last = returns_predictions(path_to_fine_tuned_model_last, differences=True)\n",
    "incorrect_df_sexist = returns_predictions(path_to_sexist_model, differences=True)\n",
    "\n",
    "## Word Cloud\n",
    "fig, ax = plt.subplots(1, 4, sharey=True, figsize=(20, 20))\n",
    "fig.suptitle(\"Words in Incorrectly Labeled Corpus\")\n",
    "for i in range(0, 4):\n",
    "    ax[i].xaxis.set_visible(False)\n",
    "    ax[i].yaxis.set_visible(False)\n",
    "    ax[i].set_title(titles[i])\n",
    "ax[0].imshow(draw_wordcloud(incorrect_df_original['text']))\n",
    "ax[1].imshow(draw_wordcloud(incorrect_df_all['text']))\n",
    "ax[2].imshow(draw_wordcloud(incorrect_df_last['text']))\n",
    "ax[3].imshow(draw_wordcloud(incorrect_df_sexist['text']))\n",
    "plt.plot()\n",
    "plt.savefig(fig_path+\"words_in_incorretly_labelled_text.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
